---
AWSTemplateFormatVersion: '2010-09-09'
Description: Lambda to collect Org data and store in S3
Parameters:
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket that is created to hold org data
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  ManagementRoleName:
    Type: String
    Description: The name of the IAM role that will be deployed in the management account which can retrieve AWS Organization data. KEEP THE SAME AS WHAT IS DEPLOYED INTO MANAGEMENT ACCOUNT
  ManagementAccountID:
    Type: String
    AllowedPattern: ([a-z0-9\-, ]*?$)
    Description: "(Ex: 123456789,098654321,789054312) List of Payer IDs you wish to collect data for. Can just be one Accounts"
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: organization
  DatabaseName:
    Type: String
    Description: Athena Database name where you table will be created
    Default: optimization_data
  CURTable:
    Type: String
    Description: Athena Table with CUR
    Default: cid_cur.cur
  GlueRoleARN:
    Type: String
  RolePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  Schedule:
    Type: String
    Description: Cron job to trigger the lambda using cloudwatch event
    Default: "rate(14 days)"
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
Outputs:
  LambdaFunctionName:
    Value: !Ref LambdaFunction
  LambdaFunctionARN:
    Description: Lambda function ARN.
    Value: !GetAtt LambdaFunction.Arn
Resources:
  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${RolePrefix}${CFDataName}-Lambda-Collect'
      Description: Well Architected Lab - Collecting Accounts
      Runtime: python3.8
      Code:
        ZipFile: |
          #!/usr/bin/env python3
          """ Get Account info from AWS Organizations and store on s3 bucket
          """
          import os
          import json
          import logging
          import datetime
          from functools import lru_cache

          import boto3
          from botocore.exceptions import ClientError
          from botocore.client import Config

          BUCKET = os.environ["BUCKET_NAME"]
          PREFIX = os.environ["PREFIX"]
          CRAWLER = os.environ["CRAWLER"]
          ROLE_NAME = os.environ['ROLE']
          MANAGEMENT_ACCOUNT_IDS = os.environ['MANAGEMENT_ACCOUNT_IDS']

          logger = logging.getLogger(__name__)
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              print(json.dumps(event))
              for management_account_id in [r.strip() for r in MANAGEMENT_ACCOUNT_IDS.split(',')]:
                  try:
                      process_management_acc(management_account_id)
                  except Exception as exc:
                      logging.warning(exc)
              start_crawler(CRAWLER)

          def process_management_acc(management_account_id):
              """Get info from management account and write to s3"""
              logger.info(f'Assuming role {ROLE_NAME} in {management_account_id}')
              cred = boto3.client('sts').assume_role(
                  RoleArn=f"arn:aws:iam::{management_account_id}:role/{ROLE_NAME}",
                  RoleSessionName="data_collection"
              )['Credentials']
              client = boto3.client(
                  "organizations",
                  region_name="us-east-1", #This MUST be us-east-1 regardless of region of Lambda
                  aws_access_key_id=cred['AccessKeyId'],
                  aws_secret_access_key=cred['SecretAccessKey'],
                  aws_session_token=cred['SessionToken'],
              )
              accounts = list(OrgController(client).iterate_accounts())
              logger.debug(f'Uploading {len(accounts)} records')
              s3_upload(management_account_id, accounts)


          def s3_upload(payer_id, data):
              """Upload records to s3"""
              tmp_file = f'/tmp/accounts-{payer_id}.json'
              with open(tmp_file, 'w', encoding='utf-8') as file_:
                  for line in data:
                      file_.write(json.dumps(line, default=json_converter) + '\n')
              try:
                  prefix = f"{PREFIX}/{PREFIX}-data/payer_id={payer_id}/acc-org.json" # No time/date info. Each time we override data
                  boto3.client('s3').upload_file(tmp_file, BUCKET, prefix)
                  logger.info(f"Uploaded {len(data)} records in s3://{BUCKET}/{prefix}")
              except Exception as exc:
                  logger.error(exc)

          def start_crawler(crawler):
              """start crawler"""
              try:
                  boto3.client("glue").start_crawler(Name=crawler)
                  logger.info(f"{crawler} has been started")
              except Exception as exc:
                  logging.warning(exc)

          def json_converter(obj):
              """ Help json encode date"""
              if isinstance(obj, datetime.datetime):
                  return obj.strftime("%Y-%d-%m %H:%M:%S")
              return obj

          class OrgController():
              """ AWS Organizations controller """
              def __init__(self, client):
                  self.org = client

              @lru_cache(maxsize=10000)
              def get_ou_name(self, id_):
                  """get ou name"""
                  resp = self.org.describe_organizational_unit(OrganizationalUnitId=id_)
                  return resp['OrganizationalUnit']['Name']

              @lru_cache(maxsize=10000)
              def get_parent(self, id_):
                  """list parents of account or ou"""
                  return self.org.list_parents(ChildId=id_)['Parents'][0]

              @lru_cache(maxsize=10000)
              def get_ou_path(self, id_):
                  """returns a list of OUs up to Root level"""
                  path = []
                  current = {'Id': id_}
                  while current.get('Type') != 'ROOT':
                      current = self.get_parent(current['Id'])
                      if current.get('Type') == 'ORGANIZATIONAL_UNIT':
                          current['Name'] = self.get_ou_name(current['Id'])
                      elif current.get('Type') == 'ROOT':
                          # If there are 2 or more orgs we can use a tag 'Name' to set the name of the root OU
                          # otherwise we will use ID
                          tags = self.get_tags(current["Id"])
                          current['Name'] = tags.get('Name', f'ROOT({current["Id"]})')
                      path.append(current)
                  return path[::-1]

              @lru_cache(maxsize=10000)
              def get_tags(self, id_):
                  """returns a dict of tags"""
                  paginator = self.org.get_paginator("list_tags_for_resource")
                  tags = sum([resp['Tags'] for resp in paginator.paginate(ResourceId=id_)], [])
                  return {tag['Key']: tag['Value'] for tag in tags}

              @lru_cache(maxsize=10000)
              def get_hierarchy_tags(self, id_):
                  """returns a dict of tags, updated according AWS Org hierarchy"""
                  tags = {}
                  full_path = self.get_ou_path(id_) + [{'Id': id_}]
                  for level in full_path:
                      tags.update(self.get_tags(level['Id']))
                  return tags

              def iterate_accounts(self):
                  """iterate over accounts"""
                  for page in self.org.get_paginator('list_accounts').paginate():
                      for account in page['Accounts']:
                          logger.info('processing %s', account['Id'])
                          account['Hierarchy'] = self.get_ou_path(account['Id'])
                          account['HierarchyPath'] = ' > '.join([
                              lvl.get('Name', lvl.get('Id')) for lvl in account['Hierarchy']
                          ])
                          account['HierarchyTags'] = self.get_hierarchy_tags(account['Id'])
                          account['ManagementAccountId'] =  account['Arn'].split(':')[4]
                          account['Parent'] = account['Hierarchy'][-1].get('Name')
                          account['ParentId'] = account['Hierarchy'][-1].get('Id')
                          account['ParentTags'] = self.get_tags(account['ParentId'])
                          #account['Parent_Tags'] = self.get_tags(account['ParentId']) # Uncomment for Backward Compatibility
                          logger.debug(json.dumps(account, indent=2, default=json_converter))
                          yield account

          def test():
              """ local test """
              client = boto3.client(
                  'organizations',
                  region_name="us-east-1", #MUST be us-east-1 regardless of region you have the Lambda
              )
              for account in OrgController(client).iterate_accounts():
                  print(json.dumps(account, default=json_converter))


      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 600
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          CRAWLER: !Ref OrgCrawler
          ROLE: !Ref ManagementRoleName
          MANAGEMENT_ACCOUNT_IDS: !Ref ManagementAccountID
          PREFIX: !Ref CFDataName
  OrgCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${RolePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${RolePrefix}Lambda-Role-${CFDataName}"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: "Assume-Management-Organization-Data-Role"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:aws:iam::*:role/${ManagementRoleName}" # Need to assume a Read role in all Management Accounts
        - PolicyName: "CloudWatch-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                  - "logs:DescribeLogStreams"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/Lambda_Organization_Data_Collector*"
              - Effect: "Allow"
                Action:
                  - "glue:StartCrawler"
                Resource: !Sub "arn:aws:glue:${AWS::Region}:${AWS::AccountId}:crawler/${OrgCrawler}"
        - PolicyName: !Sub "${CFDataName}-S3-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource:
                  - !Sub "arn:aws:s3:::${DestinationBucket}/*"
  AthenaQuery:
      Type: AWS::Athena::NamedQuery
      Properties:
        Database: !Ref DatabaseName
        Description: Provides a cur extended with organization info
        Name: !Sub '${RolePrefix}view cur_with_org_data'
        QueryString: !Sub |
          CREATE OR REPLACE VIEW cur_with_org_data AS
          SELECT *
          FROM ("${CURTable}" cur
          INNER JOIN "${DatabaseName}"."organization_data"
            ON ("cur"."line_item_usage_account_id" = "${DatabaseName}"."organization_data"."id"))
  CloudWatchTrigger:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Notification Event for ${RolePrefix}${CFDataName} data collection"
      Name: !Sub "${RolePrefix}${CFDataName}-Scheduler"
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      Targets:
        - Arn: !GetAtt LambdaFunction.Arn
          Id: TriggerLambda
  EventPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt LambdaFunction.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt CloudWatchTrigger.Arn
  LambdaAnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName
