AWSTemplateFormatVersion: '2010-09-09'
Description: Retrieves Budgets data
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to be created to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  MultiAccountRoleName:
    Type: String
    Description: Name of the IAM role deployed in all accounts which can retrieve AWS Data.
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: budgets
  GlueRoleARN:
    Type: String
    Description: Arn for the Glue Crawler role
  Schedule:
    Type: String
    Description: EventBridge Schedule to trigger the data collection
    Default: "rate(14 days)"
  ResourcePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
  AccountCollectorLambdaARN:
    Type: String
    Description: Arn of the Account Collector Lambda
  StepFunctionTemplate:
    Type: String
    Description: JSON representation of common StepFunction template
  StepFunctionExecutionRoleARN:
    Type: String
    Description: Common role for Step Function execution
  SchedulerExecutionRoleARN:
    Type: String
    Description: Common role for module Scheduler execution

Outputs:
  StepFunctionARN:
    Description: ARN for the module's Step Function
    Value: !GetAtt ModuleStepFunction.Arn

Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ResourcePrefix}${CFDataName}-LambdaRole"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: !Sub "${CFDataName}-MultiAccount-LambdaRole"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:aws:iam::*:role/${MultiAccountRoleName}"
        - PolicyName: "S3Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource:
                  - !Sub "${DestinationBucketARN}/*"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: "Need explicit name to identify role actions"

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ResourcePrefix}${CFDataName}-Lambda'
      Description: !Sub "Lambda function to retrieve ${CFDataName}"
      Runtime: python3.10
      Architectures: [x86_64]
      Code:
        ZipFile: |
          import os
          import json
          import logging
          from datetime import date, timedelta, datetime

          import boto3

          logger = logging.getLogger(__name__)
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))
          #logger.setLevel(logging.DEBUG)

          # Helper classes and functions
          class CidError(Exception):
              def __init__(self, message="", exc=None):
                  excmsg = exc.message if exc and hasattr(exc, 'message') else ""
                  message = f"({type(exc).__name__}) exception. {excmsg} {message}" if exc else message
                  if type(self) == CidNonCriticalError.__class__:
                      logger.warning(message)
                  else:
                      logger.error(message)
                  super().__init__(message)
          class CidNonCriticalError(CidError):
              def __init__(self, message="", exc=None):
                  super().__init__(message, exc)
          class CidCriticalError(CidError):
              def __init__(self, message="", exc=None):
                  super().__init__(message, exc)
          class ClientAccessError(Exception):
              def __init__(self, exc, role_name, account_id, service, region):
                  message = f"({type(exc).__name__}) exception: '{exc}' when getting '{service}' client with role '{role_name}' from account '{account_id}' in region '{region}'"
                  logger.warning(message)
                  super().__init__(message)

          class Params():
              def __init__(self, env):
                  try:
                      self.bucket = env["BUCKET_NAME"]
                      self.role_name = env["ROLENAME"]
                      self.module_name = env["PREFIX"]
                      self.tmp_file = "/tmp/tmp.json"
                      self.collection_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                      self.boto_config = None
                  except (KeyError, AttributeError):
                      raise CidCriticalError(f"Invalid environment params {env}")

          class Account():
              def __init__(self, account_json: dict):
                  try:
                      self.account_id = account_json["account_id"]
                      self.account_name = account_json["account_name"]
                      self.payer_id = account_json["payer_id"]
                  except KeyError:
                      raise CidCriticalError(f"Invalid account data passed {account_json}")

          def to_json(obj):
              return json.dumps(
                  obj,
                  default=lambda x:
                      x.isoformat() if isinstance(x, (date, datetime)) else None
              )

          # Core implementation
          def lambda_handler(event, context):
              logger.info(f"Incoming event: {json.dumps(event)}")
              status_code = 500
              try:
                  account = Account(json.loads(event["account"]))
                  params = Params(os.environ)
                  logger.debug(params)
                  main(account, params)
                  status_code = 200

              except KeyError as exc:
                  raise CidCriticalError(f"Account is not defined the Lambda event. Please do not trigger this Lambda manually. Use the corresponding {os.environ['PREFIX']} state machine in Step Functions instead.")
              except CidNonCriticalError as exc:
                  status_code = 200
              except CidCriticalError as exc:
                  raise exc
              except Exception as exc:
                  raise CidCriticalError(f"(UnhandledExceptionError) in {os.environ['PREFIX']} module", exc)
              finally:
                  return {"statusCode": status_code}

          def main(account, params):
              logger.debug("Entering main")
              data_uploaded = False
              records = get_api_data(account, params)
              if len(records) > 0:
                  count = store_to_temp(records, params, account)
                  if count > 0:
                      upload_to_s3(account, params)
                      data_uploaded = True
              if not data_uploaded:
                  logger.info("No file uploaded because no new records were found")

          def get_api_data(account, params):
              logger.debug("Entering get_api_data")
              client = get_client_with_role(params.role_name, account.account_id, region="us-east-1", service="budgets", params)
              results = []
              paginator = client.get_paginator("describe_budgets")
              page_iterator = paginator.paginate(AccountId=account.account_id)
              for page in page_iterator:
                  if not 'Budgets' in page: continue
                  for record in page['Budgets']:
                      output = parse_record(record, params, account)
                      results.append(output)
              logger.debug(results)
              logger.info(f"API results total {len(results)}")
              return results

          def parse_record(record, params=None, account=None):
              logger.debug(f"Entering parse_record for {record}")
              result = record
              try:
                  result['collection_time'] = params.collection_time
                  record.update({'Account_ID': account.account_id, 'Account_Name': account.account_name})
                  if 'CostFilters' not in result or len(result['CostFilters']) == 0 or 'PlannedBudgetLimits' not in result:
                      result.update({'CostFilters': {'Filter': ['None']}})
                  logger.debug(f"Processing record complete")
                  return result

              except Exception as exc:
                  raise CidCriticalError(f"Unhandled exception in parse_record", exc)

          def store_to_temp(results, params, account):
              logger.debug("Entering store_to_temp")
              count = 0
              try:
                  with open(params.tmp_file, "w", encoding='utf-8') as f:
                      for result in results:
                          f.write(to_json(record))
                          f.write("\n")
                          count += 1

              except CidCriticalError as exc:
                  raise exc
              except Exception as exc:
                  raise CidCriticalError(f"Unhandled exception in store_to_temp", exc)

              logger.info(f"Stored records in temp for account {account.account_id}")
              return count

          def upload_to_s3(account, params):
              logger.debug(f"Entering upload_to_s3 for bucket {params.bucket}")
              try:
                  key = datetime.now().strftime(f"{params.module_name}/{params.module_name}-data/payer_id={account.payer_id}/year=%Y/month=%m/day=%d/{params.module_name}-%Y-%m-%d.json")
                  res = boto3.client('s3').upload_file(params.tmp_file, params.bucket, key)
                  logger.info(f"Data stored to s3://{params.bucket}/{key}")

              except Exception as exc:
                  raise CidFatalError(exc)

          def get_client_with_role(role_name, account_id, service, region, params):
              logger.debug(f"Entering get_client_with_role to get '{service}' client with role '{role_name}' from account '{account_id}' in region '{region}'")
              try:
                  credentials = boto3.client('sts').assume_role(
                      RoleArn=f"arn:aws:iam::{account_id}:role/{role_name}",
                      RoleSessionName="data_collection"
                  )['Credentials']
                  logger.debug("Successfully assumed role, now getting client")
                  client = boto3.client(
                      service,
                      region_name = region,
                      aws_access_key_id = credentials['AccessKeyId'],
                      aws_secret_access_key = redentials['SecretAccessKey'],
                      aws_session_token = credentials['SessionToken'],
                      config = params.boto_config
                  )
                  logger.info(f"Successfully created '{service}' client with role '{role_name}' from account '{account_id}' in region '{region}'")
                  return client

              except Exception as exc:
                  raise ClientAccessError(exc, role_name, account_id, service, region)
      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 300
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          PREFIX: !Ref CFDataName
          ROLENAME: !Ref MultiAccountRoleName

    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: "No need for VPC in this case"
          - id: W92 #  Lambda functions should define ReservedConcurrentExecutions to reserve simultaneous executions
            reason: "No need for simultaneous execution"

  Crawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"

  ModuleStepFunction:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub '${ResourcePrefix}${CFDataName}-StateMachine'
      StateMachineType: STANDARD
      RoleArn: !Ref StepFunctionExecutionRoleARN
      DefinitionString: !Ref StepFunctionTemplate
      DefinitionSubstitutions:
        AccountCollectorLambdaARN: !Ref AccountCollectorLambdaARN
        ModuleLambdaARN: !GetAtt LambdaFunction.Arn
        Crawlers: !Sub '["${ResourcePrefix}${CFDataName}-Crawler"]'
        CollectionType: 'LINKED'
        Params: ''
        Module: !Ref CFDataName
        DeployRegion: !Ref AWS::Region
        Account: !Ref AWS::AccountId
        Prefix: !Ref ResourcePrefix

  ModuleRefreshSchedule:
    Type: 'AWS::Scheduler::Schedule'
    Properties:
      Description: !Sub 'Scheduler for the ODC ${CFDataName} module'
      Name: !Sub '${ResourcePrefix}${CFDataName}-RefreshSchedule'
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      FlexibleTimeWindow:
        Mode: 'OFF'
      Target:
          Arn: !GetAtt ModuleStepFunction.Arn
          RoleArn: !Ref SchedulerExecutionRoleARN

  LambdaAnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName

  AthenaQuery:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: !Sub "Provides a summary view of the ${CFDataName}"
      Name: !Sub "${CFDataName}_view"
      QueryString:
        CREATE OR REPLACE VIEW budgets_view AS
        SELECT
          budgetname budget_name
        , CAST(budgetlimit.amount AS decimal) budget_amount
        , CAST(calculatedspend.actualspend.amount AS decimal) actualspend
        , CAST(calculatedspend.forecastedspend.amount AS decimal) forecastedspend
        , timeunit
        , budgettype budget_type
        , account_id
        , timeperiod.start start_date
        , timeperiod."end"  end_date
        , year budget_year
        , month budget_month
        FROM
          optimization_data.budgets_data
        WHERE (budgettype = 'COST')  AND costfilters.filter[1] = 'None'
