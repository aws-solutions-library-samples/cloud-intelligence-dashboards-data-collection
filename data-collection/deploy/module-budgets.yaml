AWSTemplateFormatVersion: '2010-09-09'
Description: Retrieves Budgets data
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to be created to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  MultiAccountRoleName:
    Type: String
    Description: Name of the IAM role deployed in all accounts which can retrieve AWS Data.
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: budgets
  GlueRoleARN:
    Type: String
    Description: Arn for the Glue Crawler role
  Schedule:
    Type: String
    Description: EventBridge Schedule to trigger the data collection
    Default: "rate(1 day)"
  ResourcePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
  AccountCollectorLambdaARN:
    Type: String
    Description: Arn of the Account Collector Lambda
  CodeBucket:
    Type: String
    Description: Source code bucket
  StepFunctionTemplate:
    Type: String
    Description: S3 key to the JSON template for the StepFunction
  StepFunctionExecutionRoleARN:
    Type: String
    Description: Common role for Step Function execution
  SchedulerExecutionRoleARN:
    Type: String
    Description: Common role for module Scheduler execution
  DataBucketsKmsKeysArns:
    Type: String
    Description: "ARNs of KMS Keys for data buckets and/or Glue Catalog. Comma separated list, no spaces. Keep empty if data Buckets and Glue Catalog are not Encrypted with KMS. You can also set it to '*' to grant decrypt permission for all the keys."
    Default: ""

Outputs:
  StepFunctionARN:
    Description: ARN for the module's Step Function
    Value: !GetAtt ModuleStepFunction.Arn
Conditions:
  NeedDataBucketsKms: !Not [ !Equals [ !Ref DataBucketsKmsKeysArns, "" ] ]
Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ResourcePrefix}${CFDataName}-LambdaRole"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - !Sub "lambda.${AWS::URLSuffix}"
        Version: 2012-10-17
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Path: /
      Policies:
        - PolicyName: !Sub "${CFDataName}-MultiAccount-LambdaRole"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:${AWS::Partition}:iam::*:role/${MultiAccountRoleName}"
        - PolicyName: "S3Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource:
                  - !Sub "${DestinationBucketARN}/*"
        - !If
          - NeedDataBucketsKms
          - PolicyName: "KMS"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - "kms:GenerateDataKey"
                  Resource: !Split [ ',', !Ref DataBucketsKmsKeysArns ]
          - !Ref AWS::NoValue
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: "Need explicit name to identify role actions"

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ResourcePrefix}${CFDataName}-Lambda'
      Description: !Sub "Lambda function to retrieve ${CFDataName}"
      Runtime: python3.13
      Architectures: [x86_64]
      Code:
        ZipFile: |
          #Authors:
          # Stephanie Gooch - initial version
          # Mohideen - Added Budgets tag collection module
          import os
          import json
          import re
          import logging
          import datetime
          from json import JSONEncoder

          import boto3

          BUCKET = os.environ["BUCKET_NAME"]
          PREFIX = os.environ["PREFIX"]
          ROLE_NAME = os.environ['ROLE_NAME']
          TMP_FILE = "/tmp/data.json"

          logger = logging.getLogger(__name__)
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))

          class DateTimeEncoder(JSONEncoder):
              """encoder for json with time object"""
              def default(self, o):
                  if isinstance(o, (datetime.date, datetime.datetime)):
                      return o.isoformat()
                  return None

          def clean_value(value):
              """Clean string values by replacing special characters with underscores"""
              if isinstance(value, str):
                  return re.sub(r'\W+', '_', value)
              elif isinstance(value, list):
                  return [clean_value(v) for v in value]
              return value

          def process_cost_filters(budget):
              """Process and clean cost filters in budget"""
              cost_filters = budget.get('CostFilters', {})
              if not cost_filters:
                  budget['CostFilters'] = {'Filter': ['None']}
                  return

              cleaned_filters = {
                  re.sub(r'\W+', '_', key): clean_value(value)
                  for key, value in cost_filters.items()
              }
              budget['CostFilters'] = cleaned_filters

          def assume_role(account_id, service, region):
              partition = boto3.session.Session().get_partition_for_region(region_name=region)
              cred = boto3.client('sts', region_name=region).assume_role(
                  RoleArn=f"arn:{partition}:iam::{account_id}:role/{ROLE_NAME}",
                  RoleSessionName="data_collection"
              )['Credentials']
              return boto3.client(
                  service,
                  aws_access_key_id=cred['AccessKeyId'],
                  aws_secret_access_key=cred['SecretAccessKey'],
                  aws_session_token=cred['SessionToken']
              )

          def collect_budget_history(budgets_client, account_id, account_name, payer_id, budget_name, aws_partition, prev_month_date):
              """Collect historical budget data for previous month"""
              try:
                  prev_month_start = prev_month_date.replace(day=1)
                  next_month = (prev_month_date.replace(day=28) + datetime.timedelta(days=4)).replace(day=1)
                  prev_month_end = next_month - datetime.timedelta(days=1)
                  
                  history = budgets_client.describe_budget_performance_history(
                      AccountId=account_id,
                      BudgetName=budget_name,
                      TimePeriod={
                          'Start': prev_month_start,
                          'End': prev_month_end
                      }
                  )
                  
                  if not history.get('BudgetPerformanceHistory'):
                      return None
                      
                  perf_history = history['BudgetPerformanceHistory']
                  budgeted_and_actual = perf_history.get('BudgetedAndActualAmountsList', [])
                  
                  if not budgeted_and_actual:
                      return None
                  
                  # Get the last entry which has the complete month data
                  last_entry = budgeted_and_actual[-1]
                  
                  # Construct budget object from history
                  budget_hist = {
                      'BudgetName': budget_name,
                      'BudgetLimit': perf_history.get('BudgetLimit', {}),
                      'CostFilters': perf_history.get('CostFilters', {'Filter': ['None']}),
                      'CostTypes': perf_history.get('CostTypes', {}),
                      'TimeUnit': perf_history.get('TimeUnit', 'MONTHLY'),
                      'TimePeriod': last_entry.get('TimePeriod', {}),
                      'CalculatedSpend': {
                          'ActualSpend': last_entry.get('ActualAmount', {}),
                          'ForecastedSpend': last_entry.get('ActualAmount', {})
                      },
                      'BudgetType': perf_history.get('BudgetType', 'COST'),
                      'collection_time': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                      'Account_ID': account_id,
                      'Account_Name': account_name,
                      'Tags': [],
                      'PlannedBudgetLimits_Flat': [],
                      'is_historical': True
                  }
                  
                  # Fetch tags
                  budget_tags = budgets_client.list_tags_for_resource(ResourceARN=f"arn:{aws_partition}:budgets::{account_id}:budget/{budget_name}")
                  budget_hist['Tags'] = budget_tags.get('ResourceTags') or []
                  
                  process_cost_filters(budget_hist)
                  return budget_hist
                  
              except Exception as exc:
                  logger.warning(f"Failed to collect history for budget {budget_name}: {exc}")
                  return None

          def lambda_handler(event, context): #pylint: disable=W0613
              logger.info(f"Event data {json.dumps(event)}")
              if 'account' not in event:
                  raise ValueError(
                      "Please do not trigger this Lambda manually."
                      "Find the corresponding state machine in Step Functions and Trigger from there."
                  )
              now = datetime.datetime.now()
              collection_time = now.strftime("%Y-%m-%d %H:%M:%S")
              aws_partition = boto3.session.Session().get_partition_for_region(boto3.session.Session().region_name)
              account = json.loads(event["account"])
              account_id = account["account_id"]
              account_name = account["account_name"]
              payer_id = account["payer_id"]
              
              # Check if we should collect previous month's historical data
              collect_history = now.day <= 3
              prev_month_date = (now.replace(day=1) - datetime.timedelta(days=1)) if collect_history else None

              logger.info(f"Collecting data for account: {account_id}")
              try:
                  budgets_client = assume_role(account_id, "budgets", "us-east-1") # must be us-east-1
                  count = 0
                  hist_count = 0
                  
                  # Collect current budgets
                  with open(TMP_FILE, "w", encoding='utf-8') as f:
                      for budget in budgets_client.get_paginator("describe_budgets").paginate(AccountId=account_id).search('Budgets'):
                          if not budget:
                              continue
                          budget['collection_time'] = collection_time
                          budget['is_historical'] = False
                          budget_name = budget['BudgetName']
                          budget_tags = budgets_client.list_tags_for_resource(ResourceARN=f"arn:{aws_partition}:budgets::{account_id}:budget/{budget_name}")
                          budget.update({
                              'Account_ID': account_id,
                              'Account_Name': account_name,
                              'Tags': budget_tags.get('ResourceTags') or []
                          })
                          process_cost_filters(budget)
                          budget_limits = budget.pop('PlannedBudgetLimits', {}) 
                          budget['PlannedBudgetLimits_Flat'] = [
                              {'date': key, 'Amount': value.get('Amount'), 'Unit': value.get('Unit')}
                              for key, value in budget_limits.items()
                          ]
                          f.write(json.dumps(budget, cls=DateTimeEncoder) + "\n")
                          count += 1
                  
                  logger.info(f"Current budgets collected: {count}")
                  s3_upload(account_id, payer_id)
                  
                  # Collect historical data for previous month if in first 3 days
                  if collect_history:
                      logger.info(f"Collecting previous month historical data for {prev_month_date.strftime('%Y-%m')}")
                      with open(TMP_FILE, "w", encoding='utf-8') as f:
                          for budget in budgets_client.get_paginator("describe_budgets").paginate(AccountId=account_id).search('Budgets'):
                              if not budget:
                                  continue
                              budget_name = budget['BudgetName']
                              hist_budget = collect_budget_history(budgets_client, account_id, account_name, payer_id, budget_name, aws_partition, prev_month_date)
                              if hist_budget:
                                  f.write(json.dumps(hist_budget, cls=DateTimeEncoder) + "\n")
                                  hist_count += 1
                      
                      if hist_count > 0:
                          logger.info(f"Historical budgets collected: {hist_count}")
                          s3_upload_historical(account_id, payer_id, prev_month_date)
                      else:
                          logger.info("No historical budget data collected")
                  
              except Exception as exc: #pylint: disable=broad-exception-caught
                  if "AccessDenied" in str(exc):
                      print(f'Failed to assume role {ROLE_NAME} in account {account_id}. Please make sure the role exists. {exc}')
                  else:
                      print(f'{exc}. Gracefully exiting from Lambda so we do not break all StepFunction Execution')
                  return

          def s3_upload(account_id, payer_id):
              if os.path.getsize(TMP_FILE) == 0:
                  logger.info(f"No data in file for {PREFIX}")
                  return
              key = datetime.datetime.now().strftime(f"{PREFIX}/{PREFIX}-data/payer_id={payer_id}/year=%Y/month=%m/budgets-{account_id}.json")
              boto3.client('s3').upload_file(TMP_FILE, BUCKET, key)
              logger.info(f"Budget data for {account_id} stored at s3://{BUCKET}/{key}")
          
          def s3_upload_historical(account_id, payer_id, prev_month_date):
              if os.path.getsize(TMP_FILE) == 0:
                  logger.info(f"No historical data in file for {PREFIX}")
                  return
              key = prev_month_date.strftime(f"{PREFIX}/{PREFIX}-data/payer_id={payer_id}/year=%Y/month=%m/budgets-{account_id}.json")
              boto3.client('s3').upload_file(TMP_FILE, BUCKET, key)
              logger.info(f"Historical budget data for {account_id} stored at s3://{BUCKET}/{key}")

      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 300
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          PREFIX: !Ref CFDataName
          ROLE_NAME: !Ref MultiAccountRoleName

    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: "No need for VPC in this case"
          - id: W92 #  Lambda functions should define ReservedConcurrentExecutions to reserve simultaneous executions
            reason: "No need for simultaneous execution"

  LogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/lambda/${LambdaFunction}"
      RetentionInDays: 60

  Crawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"
      Configuration: |
        {
          "Version": 1.0,
          "Grouping": {
            "TableGroupingPolicy": "CombineCompatibleSchemas"
          },
          "CrawlerOutput": {
            "Partitions": {
              "AddOrUpdateBehavior": "InheritFromTable"
            },
            "Tables": {
              "TableThreshold": 1,
              "AddOrUpdateBehavior": "MergeNewColumns"
            }
          }
        }
      SchemaChangePolicy:
        UpdateBehavior: UPDATE_IN_DATABASE
        DeleteBehavior: LOG
  ModuleStepFunction:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub '${ResourcePrefix}${CFDataName}-StateMachine'
      StateMachineType: STANDARD
      RoleArn: !Ref StepFunctionExecutionRoleARN
      DefinitionS3Location:
        Bucket: !Ref CodeBucket
        Key: !Ref StepFunctionTemplate
      DefinitionSubstitutions:
        AccountCollectorLambdaARN: !Ref AccountCollectorLambdaARN
        ModuleLambdaARN: !GetAtt LambdaFunction.Arn
        Crawlers: !Sub '["${ResourcePrefix}${CFDataName}-Crawler"]'
        CollectionType: 'LINKED'
        Params: ''
        Module: !Ref CFDataName
        DeployRegion: !Ref AWS::Region
        Account: !Ref AWS::AccountId
        Prefix: !Ref ResourcePrefix
        Bucket: !Ref DestinationBucket

  ModuleRefreshSchedule:
    Type: 'AWS::Scheduler::Schedule'
    Properties:
      Description: !Sub 'Scheduler for the ODC ${CFDataName} module'
      Name: !Sub '${ResourcePrefix}${CFDataName}-RefreshSchedule'
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      FlexibleTimeWindow:
        MaximumWindowInMinutes: 30
        Mode: 'FLEXIBLE'
      Target:
        Arn: !GetAtt ModuleStepFunction.Arn
        RoleArn: !Ref SchedulerExecutionRoleARN

  AnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName

  AthenaQuery:
    Type: AWS::Athena::NamedQuery
    Properties:
      Database: !Ref DatabaseName
      Description: !Sub "Provides a summary view of the ${CFDataName}"
      Name: !Sub "${CFDataName}_view"
      QueryString: !Sub |
        CREATE OR REPLACE VIEW budgets_view AS
        SELECT
          budgetname budget_name
        , CAST(budgetlimit.amount AS decimal) budget_amount
        , CAST(calculatedspend.actualspend.amount AS decimal) actualspend
        , CAST(calculatedspend.forecastedspend.amount AS decimal) forecastedspend
        , timeunit
        , budgettype budget_type
        , account_id
        , timeperiod.start start_date
        , timeperiod."end"  end_date
        , year budget_year
        , month budget_month
        FROM
          ${DatabaseName}.budgets_data
        WHERE (budgettype = 'COST')  AND costfilters.filter[1] = 'None'
