AWSTemplateFormatVersion: '2010-09-09'
Description: Retrieves Inventory data for the chosen service
Parameters:
  DatabaseName:
    Type: String
    Description: Name of the Athena database to be created to hold lambda information
    Default: optimization_data
  DataBucketsKmsKeysArns:
    Type: String
    Description: KMS Key ARNs used for encrypting data in S3 buckets (comma separated)
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket to be created to hold data information
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  DestinationBucketARN:
    Type: String
    Description: ARN of the S3 Bucket that exists or needs to be created to hold rightsizing information
  MultiAccountRoleName:
    Type: String
    Description: Name of the IAM role deployed in all accounts which can retrieve AWS Data.
  CFDataName:
    Type: String
    Description: The name of what this cf is doing.
    Default: trusted-advisor
  GlueRoleARN:
    Type: String
    Description: Arn for the Glue Crawler role
  Schedule:
    Type: String
    Description: EventBridge Schedule to trigger the data collection
    Default: "rate(14 days)"
  ResourcePrefix:
    Type: String
    Description: This prefix will be placed in front of all roles created. Note you may wish to add a dash at the end to make more readable
  LambdaAnalyticsARN:
    Type: String
    Description: Arn of lambda for Analytics
  AccountCollectorLambdaARN:
    Type: String
    Description: Arn of the Account Collector Lambda
  CodeBucket:
    Type: String
    Description: Source code bucket
  StepFunctionTemplate:
    Type: String
    Description: S3 key to the JSON template for the StepFunction
  StepFunctionExecutionRoleARN:
    Type: String
    Description: Common role for Step Function execution
  SchedulerExecutionRoleARN:
    Type: String
    Description: Common role for module Scheduler execution

Outputs:
  StepFunctionARN:
    Description: ARN for the module's Step Function
    Value: !GetAtt ModuleStepFunction.Arn

Conditions:
  NeedDataBucketsKms: !Not [!Equals [!Ref DataBucketsKmsKeysArns, '']]

Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ResourcePrefix}${CFDataName}-LambdaRole"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - !Sub "lambda.${AWS::URLSuffix}"
        Version: 2012-10-17
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Path: /
      Policies:
        - !If
          - NeedDataBucketsKms
          - PolicyName: "KMS"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - "kms:GenerateDataKey"
                  Resource: !Split [ ',', !Ref DataBucketsKmsKeysArns ]
          - !Ref AWS::NoValue
        - PolicyName: "AssumeMultiAccountRole"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource: !Sub "arn:${AWS::Partition}:iam::*:role/${MultiAccountRoleName}"
        - PolicyName: "S3Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                Resource:
                  - !Sub "${DestinationBucketARN}/*"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28 # Resource found with an explicit name, this disallows updates that require replacement of this resource
            reason: "Need explicit name to identify role actions"

  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ResourcePrefix}${CFDataName}-Lambda'
      Description: !Sub "Lambda function to retrieve ${CFDataName}"
      Runtime: python3.12
      Architectures: [x86_64]
      Code:
        ZipFile: |
          import os
          import json
          import logging
          from datetime import date, datetime
          from json import JSONEncoder
          import boto3
          from botocore.client import Config

          PREFIX = os.environ["PREFIX"]
          BUCKET = os.environ["BUCKET_NAME"]
          ROLE_NAME = os.environ['ROLENAME']
          COSTONLY = os.environ.get('COSTONLY', 'no').lower() == 'yes'
          TMP_FILE = "/tmp/data.json"
          TMP_FILE_Priority = "/tmp/data_priority.json"
          REGIONS = ["us-east-1"]

          #config to avoid ThrottlingException
          config = Config(
              retries = {
                  'max_attempts': 10,
                  'mode': 'standard'
              }
          )

          logger = logging.getLogger(__name__)
          logger.setLevel(getattr(logging, os.environ.get('LOG_LEVEL', 'INFO').upper(), logging.INFO))

          def lambda_handler(event, context): #pylint: disable=unused-argument
              if 'account' not in event:
                  raise ValueError(
                      "Please do not trigger this Lambda manually."
                      "Find the corresponding state machine in Step Functions and Trigger from there."
                  )
              try:
                  account = json.loads(event["account"])
                  account_id = account["account_id"]
                  account_name = account["account_name"]
                  payer_id = account["payer_id"]

                  logger.info(f"Collecting TA for account: {account_id}")
                  filename = read_ta(account_id, account_name)
                  upload_to_s3(account_id, payer_id, "data", filename)

                  logger.info(f"Collecting TA Priority for account: {account_id}")
                  filename = read_ta_priority(account_id, account_name)
                  upload_to_s3(account_id, payer_id, "priority-data", filename)

              except Exception as e: #pylint: disable=broad-exception-caught
                  logging.warning(e)

          def upload_to_s3(account_id, payer_id, suffix, tmp_file):
              key = datetime.now().strftime(
                  f"{PREFIX}/{PREFIX}-{suffix}/payer_id={payer_id}/year=%Y/month=%m/{PREFIX}-{account_id}-%d%m%Y-%H%M%S.json"
              )

              if os.path.getsize(tmp_file) == 0:
                  print(f"No data in file for {tmp_file}")
                  return

              try:
                  boto3.client("s3").upload_file(tmp_file, BUCKET, key)
                  print(f"Data for {account_id} in s3 - {key}")
              except Exception as e: #pylint: disable=broad-exception-caught
                  print(f"{type(e)}: {e}")

          def assume_role(account_id, service, region, role):
              partition = boto3.session.Session().get_partition_for_region(region_name=region)
              assumed = boto3.client('sts', region_name=region).assume_role(
                  RoleArn=f"arn:{partition}:iam::{account_id}:role/{role}",
                  RoleSessionName='data_collection'
              )
              creds = assumed['Credentials']
              return boto3.client(service, region_name=region,
                  aws_access_key_id=creds['AccessKeyId'],
                  aws_secret_access_key=creds['SecretAccessKey'],
                  aws_session_token=creds['SessionToken'],
                  config=config,
              )

          def _json_serial(self, obj):
              return obj.isoformat() if isinstance(obj, (datetime, date)) else JSONEncoder.default(self, obj)

          def read_ta(account_id, account_name):
              with open(TMP_FILE, "w", encoding='utf-8') as f:
                  support = assume_role(account_id, "support", REGIONS[0], ROLE_NAME)
                  checks = support.describe_trusted_advisor_checks(language="en")["checks"]
                  for check in checks:
                      #print(json.dumps(check))
                      if (COSTONLY and check.get("category") != "cost_optimizing"):
                          continue
                      try:
                          result = support.describe_trusted_advisor_check_result(checkId=check["id"], language="en")['result']
                          #print(json.dumps(result))
                          if result.get("status") == "not_available":
                              continue
                          dt = result['timestamp']
                          ts = datetime.strptime(dt, '%Y-%m-%dT%H:%M:%SZ').strftime('%s')
                          for resource in result["flaggedResources"]:
                              output = {}
                              if "metadata" in resource:
                                  output.update(dict(zip(check["metadata"], resource["metadata"])))
                                  del resource['metadata']
                              resource["Region"] = resource.pop("region") if "region" in resource else '-'
                              resource["Status"] = resource.pop("status") if "status" in resource else '-'
                              output.update({"AccountId":account_id, "AccountName":account_name, "Category": check["category"], 'DateTime': dt, 'Timestamp': ts, "CheckName": check["name"], "CheckId": check["id"]})
                              output.update(resource)
                              output = {k.lower(): v for k, v in output.items()}
                              f.write(json.dumps(output, default=_json_serial) + "\n")
                      except Exception as e: #pylint: disable=broad-exception-caught
                          print(f'{type(e)}: {e}')
              return TMP_FILE

          def _isoformat(date_value, default='N/A'):
              """ Converts a datetime value to ISO format string.
              """
              return date_value.isoformat() if isinstance(date_value, datetime) else default

          def read_ta_priority(account_id, account_name):
              """ Read recommendations and write to a file
              """
              trustedadvisor = assume_role(account_id, "trustedadvisor", REGIONS[0], ROLE_NAME)
              try:
                  recommendations = (trustedadvisor
                      .get_paginator('list_recommendations')
                      .paginate(type='priority')
                      .search('recommendationSummaries[]')
                  )
                  with open(TMP_FILE_Priority, 'w', encoding='utf-8') as jsonfile:
                      for recommendation in recommendations:
                          # Get recommendation details including resolved date
                          recommendation_details = (trustedadvisor
                              .get_recommendation(recommendationIdentifier=recommendation['arn'])
                              .get('recommendation', {})
                          )
                          # Get resources for this recommendation
                          try:
                              resources = list(trustedadvisor
                                  .get_paginator('list_recommendation_resources')
                                  .paginate(recommendationIdentifier=recommendation['arn'])
                                  .search('recommendationResourceSummaries[]')
                              )
                          except trustedadvisor.exceptions.ClientError as e:
                              print(f"Error getting resources for recommendation {recommendation['arn']}: {str(e)}")
                              resources = []

                          # Base recommendation data
                          rec_data = {
                              'recommendationArn': recommendation['arn'],
                              'name': recommendation['name'],
                              'description': recommendation_details['description'],
                              'awsServices': recommendation.get('awsServices', 'N/A'),
                              'createdAt': _isoformat(recommendation['createdAt']),
                              'resolvedAt': _isoformat(recommendation_details['resolvedAt']),
                              'lastUpdatedAt': _isoformat(recommendation['lastUpdatedAt']),
                              'lifecycleStage': recommendation['lifecycleStage'],
                              'recommendationStatus': recommendation['status'],
                              'pillars': recommendation['pillars'],
                              'source': recommendation['source'],
                              'accountID': account_id,
                              'accountName': account_name
                          }
                          for resource in (resources or [{}]):
                              resource_data = rec_data.copy()
                              resource_data.update({
                                  'awsResourceId': resource.get('awsResourceId', 'N/A'),
                                  'exclusionStatus': resource.get('exclusionStatus', 'N/A'),
                                  'regionCode': resource.get('regionCode', 'N/A'),
                                  'resourceStatus': resource.get('status', 'N/A')
                              })
                              jsonfile.write(json.dumps(resource_data) + '\n')

              except Exception as e: #pylint: disable=broad-exception-caught
                  print(f"Error processing TA-Priority: {str(e)}")
                  raise
              return TMP_FILE_Priority


      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 300
      Role: !GetAtt LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref DestinationBucket
          PREFIX: !Ref CFDataName
          ROLENAME: !Ref MultiAccountRoleName
          COSTONLY: "no"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89 # Lambda functions should be deployed inside a VPC
            reason: "No need for VPC in this case"
          - id: W92 #  Lambda functions should define ReservedConcurrentExecutions to reserve simultaneous executions
            reason: "No need for simultaneous execution"

  LogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/lambda/${LambdaFunction}"
      RetentionInDays: 60

  Crawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-data/"
          - Path: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-priority-data/"
      Configuration: "{\"Version\":1.0,\"Grouping\":{\"TableGroupingPolicy\":\"CombineCompatibleSchemas\"}}"

  # Add glue table for trusted advisor priority data
  TAPriorityTable:
    Type: AWS::Glue::Table
    Properties:
      DatabaseName: !Ref DatabaseName
      CatalogId: !Ref AWS::AccountId
      TableInput:
        Name: trusted_advisor_priority_data
        TableType: EXTERNAL_TABLE
        StorageDescriptor:
          Columns:
            - Name: recommendationArn
              Type: string
            - Name: name
              Type: string
            - Name: description
              Type: string
            - Name: awsServices
              Type: string
            - Name: createdAt
              Type: string
            - Name: resolvedAt
              Type: string
            - Name: lastUpdatedAt
              Type: string
            - Name: lifecycleStage
              Type: string
            - Name: recommendationStatus
              Type: string
            - Name: pillars
              Type: string
            - Name: source
              Type: string
            - Name: accountID
              Type: string
            - Name: accountName
              Type: string
            - Name: awsResourceId
              Type: string
            - Name: exclusionStatus
              Type: string
            - Name: regionCode
              Type: string
            - Name: resourceStatus
              Type: string
          Location: !Sub "s3://${DestinationBucket}/${CFDataName}/${CFDataName}-priority-data/"
          InputFormat: org.apache.hadoop.mapred.TextInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          Parameters:
              UPDATED_BY_CRAWLER: !Sub '${ResourcePrefix}${CFDataName}-Crawler'
          SerdeInfo:
            SerializationLibrary: org.openx.data.jsonserde.JsonSerDe
            Parameters:
              paths: recommendationArn,name,description,awsServices,createdAt,resolvedAt,lastUpdatedAt,lifecycleStage,recommendationStatus,pillars,source,accountID,accountName,awsResourceId,exclusionStatus,regionCode,resourceStatus
        PartitionKeys:
          - Name: payer_id
            Type: string
          - Name: year
            Type: string
          - Name: month
            Type: string

  ModuleStepFunction:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub '${ResourcePrefix}${CFDataName}-StateMachine'
      StateMachineType: STANDARD
      RoleArn: !Ref StepFunctionExecutionRoleARN
      DefinitionS3Location:
        Bucket: !Ref CodeBucket
        Key: !Ref StepFunctionTemplate
      DefinitionSubstitutions:
        AccountCollectorLambdaARN: !Ref AccountCollectorLambdaARN
        ModuleLambdaARN: !GetAtt LambdaFunction.Arn
        Crawlers: !Sub '["${ResourcePrefix}${CFDataName}-Crawler"]'
        CollectionType: "LINKED"
        Params: ''
        Module: !Ref CFDataName
        DeployRegion: !Ref AWS::Region
        Account: !Ref AWS::AccountId
        Prefix: !Ref ResourcePrefix

  ModuleRefreshSchedule:
    Type: 'AWS::Scheduler::Schedule'
    Properties:
      Description: !Sub 'Scheduler for the ODC ${CFDataName} module'
      Name: !Sub '${ResourcePrefix}${CFDataName}-RefreshSchedule'
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      FlexibleTimeWindow:
        MaximumWindowInMinutes: 30
        Mode: 'FLEXIBLE'
      Target:
        Arn: !GetAtt ModuleStepFunction.Arn
        RoleArn: !Ref SchedulerExecutionRoleARN
        Input: !Sub '{"module_lambda":"${LambdaFunction.Arn}","crawlers": ["${ResourcePrefix}${CFDataName}-Crawler"]}'

  AnalyticsExecutor:
    Type: Custom::LambdaAnalyticsExecutor
    Properties:
      ServiceToken: !Ref LambdaAnalyticsARN
      Name: !Ref CFDataName
